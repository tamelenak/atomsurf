{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MaSIF Site Task Tutorial\n",
    "=======================\n",
    "\n",
    "This script demonstrates how to use AtomSurf for the MaSIF site task,\n",
    "which involves predicting protein-protein interaction sites on protein surfaces.\n",
    "\n",
    "The workflow includes:\n",
    "1. Data preprocessing\n",
    "2. Model training\n",
    "3. Testing and visualization\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from omegaconf import DictConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "from atomsurf.protein.create_esm import get_esm_embedding_single, get_esm_embedding_batch\n",
    "from atomsurf.utils.data_utils import AtomBatch, PreprocessDataset, SurfaceLoader, GraphLoader\n",
    "from atomsurf.utils.python_utils import do_all\n",
    "from atomsurf.utils.wrappers import DefaultLoader, get_default_model\n",
    "from atomsurf.tasks.masif_site.preprocess import PreProcessMSDataset\n",
    "from atomsurf.tasks.masif_site.model import MasifSiteNet\n",
    "from atomsurf.tasks.masif_site.data_loader import MasifSiteDataset\n",
    "\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Set up necessary directories for data processing and results.\"\"\"\n",
    "    data_dir = \"data/masif_site\"\n",
    "    benchmark_pdb_dir = os.path.join(data_dir, \"01-benchmark_pdbs\")\n",
    "    # Surface directory will include the face reduction rate in its name\n",
    "    surface_dir = os.path.join(data_dir, \"surfaces_0.5_False\")  # 0.5 is the face_reduction_rate, False for use_pymesh\n",
    "    rgraph_dir = os.path.join(data_dir, \"rgraph\")\n",
    "    esm_dir = os.path.join(data_dir, \"esm_emb\")\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(surface_dir, exist_ok=True)\n",
    "    os.makedirs(rgraph_dir, exist_ok=True)\n",
    "    os.makedirs(esm_dir, exist_ok=True)\n",
    "\n",
    "    return data_dir, benchmark_pdb_dir, surface_dir, rgraph_dir, esm_dir\n",
    "\n",
    "\n",
    "def preprocess_data(data_dir, pdb_dir, esm_dir):\n",
    "    \"\"\"Preprocess the data including surface generation and ESM embeddings.\"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    \n",
    "    # Initialize the preprocessing dataset\n",
    "    dataset = PreProcessMSDataset(\n",
    "        data_dir=data_dir,\n",
    "        recompute_s=True,  # Set to True to recompute surfaces\n",
    "        recompute_g=True,  # Set to True to recompute graphs\n",
    "        face_reduction_rate=0.5,  # Adjust this value to control mesh resolution\n",
    "        use_pymesh=True\n",
    "    )\n",
    "\n",
    "    # Run preprocessing\n",
    "    print(\"Processing surfaces and graphs...\")\n",
    "    do_all(dataset, num_workers=4)  # Adjust number of workers based on your system\n",
    "\n",
    "    # Generate ESM embeddings\n",
    "    print(\"Generating ESM embeddings...\")\n",
    "    get_esm_embedding_batch(in_pdbs_dir=pdb_dir, dump_dir=esm_dir)\n",
    "    \n",
    "    print(\"Preprocessing complete!\")\n",
    "\n",
    "\n",
    "def setup_datasets(data_dir, surface_dir, rgraph_dir, esm_dir):\n",
    "    \"\"\"Set up training and testing datasets.\"\"\"\n",
    "    # Create configuration objects for surface and graph loaders\n",
    "    \n",
    "    # Surface configuration\n",
    "    cfg_surface = DictConfig({})\n",
    "    cfg_surface.use_surfaces = True\n",
    "    cfg_surface.feat_keys = 'all'\n",
    "    cfg_surface.oh_keys = 'all'\n",
    "    cfg_surface.gdf_expand = True\n",
    "    cfg_surface.data_dir = data_dir  # The root data directory\n",
    "    cfg_surface.data_name = 'surfaces_0.5_False'  # The subdirectory containing the .pt files\n",
    "    \n",
    "    # Graph configuration\n",
    "    cfg_graph = DictConfig({})\n",
    "    cfg_graph.use_graphs = True\n",
    "    cfg_graph.feat_keys = 'all'\n",
    "    cfg_graph.oh_keys = 'all'\n",
    "    cfg_graph.esm_dir = esm_dir\n",
    "    # Re-enable ESM features now that we've fixed the one-hot encoding issue\n",
    "    cfg_graph.use_esm = True  # Changed back to True\n",
    "    cfg_graph.data_dir = data_dir  # The root data directory\n",
    "    cfg_graph.data_name = 'rgraph'  # The subdirectory containing the graph .pt files\n",
    "    \n",
    "    # Create surface and graph builders\n",
    "    surface_builder = SurfaceLoader(cfg_surface)\n",
    "    graph_builder = GraphLoader(cfg_graph)\n",
    "    \n",
    "    # Load the training systems list\n",
    "    train_systems_list = os.path.join(data_dir, 'splits', 'train_list.txt')\n",
    "    train_systems = [name.strip() for name in open(train_systems_list, 'r').readlines()]\n",
    "    \n",
    "    # Load the test systems list\n",
    "    test_systems_list = os.path.join(data_dir, 'splits', 'test_list.txt')\n",
    "    test_systems = [name.strip() for name in open(test_systems_list, 'r').readlines()]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MasifSiteDataset(\n",
    "        systems=train_systems,\n",
    "        surface_builder=surface_builder,\n",
    "        graph_builder=graph_builder\n",
    "    )\n",
    "    \n",
    "    # Debug: Check if we can load any data\n",
    "    print(f\"Number of training systems: {len(train_systems)}\")\n",
    "    for i in range(min(5, len(train_systems))):\n",
    "        system = train_systems[i]\n",
    "        print(f\"Trying to load system {system}...\")\n",
    "        surface = surface_builder.load(system)\n",
    "        graph = graph_builder.load(system)\n",
    "        print(f\"  Surface is None: {surface is None}\")\n",
    "        print(f\"  Graph is None: {graph is None}\")\n",
    "        if surface is not None and graph is not None:\n",
    "            print(f\"  Found valid data for system {system}\")\n",
    "            # Use this system for model setup\n",
    "            train_dataset.valid_idx = i\n",
    "            break\n",
    "    else:\n",
    "        print(\"ERROR: Could not find any valid data in the first 5 systems!\")\n",
    "        raise ValueError(\"No valid data found in the dataset\")\n",
    "    \n",
    "    test_dataset = MasifSiteDataset(\n",
    "        systems=test_systems,\n",
    "        surface_builder=surface_builder,\n",
    "        graph_builder=graph_builder\n",
    "    )\n",
    "    \n",
    "    # Create training data loader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=AtomBatch.from_data_list\n",
    "    )\n",
    "    \n",
    "    return train_dataset, test_dataset, train_loader\n",
    "\n",
    "\n",
    "def setup_model(train_dataset):\n",
    "    \"\"\"Initialize and set up the MaSIF site model.\"\"\"\n",
    "    # Get input dimensions from example data\n",
    "    if hasattr(train_dataset, 'valid_idx'):\n",
    "        example_data = train_dataset[train_dataset.valid_idx]\n",
    "    else:\n",
    "        # Try to find a valid example\n",
    "        for i in range(len(train_dataset)):\n",
    "            example_data = train_dataset[i]\n",
    "            if example_data is not None:\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\"No valid data found in the dataset\")\n",
    "    \n",
    "    # Create proper configuration for encoder\n",
    "    cfg_encoder = DictConfig({\n",
    "        \"blocks\": []  # Empty blocks list - the model will handle this internally\n",
    "    })\n",
    "    \n",
    "    # Create configuration for head\n",
    "    cfg_head = DictConfig({\n",
    "        \"encoded_dims\": 52,  # Changed from 32 to 52 to match the actual feature dimensions\n",
    "        \"output_dims\": 1\n",
    "    })\n",
    "\n",
    "    # Initialize the original MasifSiteNet model\n",
    "    model = MasifSiteNet(\n",
    "        cfg_encoder=cfg_encoder,\n",
    "        cfg_head=cfg_head\n",
    "    )\n",
    "\n",
    "    # Set up device and optimizer\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    return model, device, optimizer, criterion\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    \"\"\"Train the MaSIF site model.\"\"\"\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_gradl()\n",
    "                \n",
    "                # Forward pass\n",
    "                pred = model(batch)\n",
    "                # Flatten the predictions to match the target shape\n",
    "                pred = pred.x.flatten()\n",
    "                loss = criterion(pred, batch.surface.iface_labels.float())\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if batch_count > 0:\n",
    "            avg_loss = total_loss / batch_count\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, No valid batches processed')\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def visualize_predictions(vertices, faces, predictions, true_labels=None):\n",
    "    \"\"\"Visualize the predicted and true interaction sites on the protein surface.\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot predictions\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2],\n",
    "                     triangles=faces, cmap='coolwarm',\n",
    "                     array=predictions.cpu().numpy())\n",
    "    ax1.set_title('Predictions')\n",
    "    \n",
    "    if true_labels is not None:\n",
    "        # Plot true labels\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2],\n",
    "                         triangles=faces, cmap='coolwarm',\n",
    "                         array=true_labels.cpu().numpy())\n",
    "        ax2.set_title('True Labels')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dataset, device):\n",
    "    \"\"\"Evaluate the model on test data and visualize results.\"\"\"\n",
    "    print(\"Evaluating model...\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Find a valid test example\n",
    "        for i in range(min(5, len(test_dataset))):\n",
    "            test_data = test_dataset[i]\n",
    "            if test_data is not None:\n",
    "                print(f\"Using test example {i} for evaluation\")\n",
    "                test_data = test_data.to(device)\n",
    "                batch = AtomBatch.from_data_list([test_data])\n",
    "                pred = model(batch)\n",
    "                pred_labels = (torch.sigmoid(pred) > 0.5).float()\n",
    "                \n",
    "                # Visualize results\n",
    "                visualize_predictions(\n",
    "                    vertices=test_data.surface.pos.cpu(),\n",
    "                    faces=test_data.surface.face.t().cpu(),\n",
    "                    predictions=pred_labels,\n",
    "                    true_labels=test_data.surface.iface_labels\n",
    "                )\n",
    "                break\n",
    "        else:\n",
    "            print(\"Could not find a valid test example for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_masif_site_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, pdb_dir, surface_dir, rgraph_dir, esm_dir = setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_data(data_dir, pdb_dir, esm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training systems: 9007\n",
      "Trying to load system 1A0G_A...\n",
      "WARNING: Feature 'sse' had values outside the valid range [0, 7]. Values have been clamped.\n",
      "  Surface is None: False\n",
      "  Graph is None: False\n",
      "  Found valid data for system 1A0G_A\n"
     ]
    }
   ],
   "source": [
    "# Dataset setup\n",
    "train_dataset, train_loader, test_dataset = setup_datasets(data_dir, surface_dir, rgraph_dir, esm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, device, optimizer, criterion = setup_model(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (atomsurf)",
   "language": "python",
   "name": "atomsurf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

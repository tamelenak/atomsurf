{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff36044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "Labels: tensor([2, 1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch = torch.load('/root/atomsurf/debug_spike_step_6299/batches/batch_step_06299.pt')\n",
    "print(f\"Batch size: {batch['num_graphs']}\")\n",
    "print(f\"Labels: {batch['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90779ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'lig_coord', 'num_graphs', 'pocket_names', 'surface', 'graph'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfc01495",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load training dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m systems \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m pocket_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(systems\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal training samples needed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pocket_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load training dataset\n",
    "systems = pickle.load(open('/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p', 'rb'))\n",
    "pocket_names = list(systems.keys())\n",
    "\n",
    "print(f\"Total training samples needed: {len(pocket_names)}\")\n",
    "\n",
    "# Check surface files\n",
    "surface_dir = '/root/atomsurf/data/masif_ligand/surf_1.0_False'\n",
    "surface_files = os.listdir(surface_dir)\n",
    "print(f\"Surface files available: {len(surface_files)}\")\n",
    "\n",
    "# Check how many pockets have surfaces\n",
    "missing = 0\n",
    "found = 0\n",
    "\n",
    "for pocket in pocket_names[:10000]:  # Check first 100\n",
    "    surf_file = os.path.join(surface_dir, f\"{pocket}.pt\")\n",
    "    if os.path.exists(surf_file):\n",
    "        found += 1\n",
    "    else:\n",
    "        missing += 1\n",
    "\n",
    "print(f\"\\nFirst 100 samples:\")\n",
    "print(f\"  Found: {found}\")\n",
    "print(f\"  Missing: {missing}\")\n",
    "print(f\"  Missing rate: {missing/(found+missing)*100}%\")\n",
    "\n",
    "# Show sample names\n",
    "print(f\"\\nSample pocket name: {pocket_names[0]}\")\n",
    "print(f\"Expected file: {os.path.join(surface_dir, pocket_names[0] + '.pt')}\")\n",
    "print(f\"Exists: {os.path.exists(os.path.join(surface_dir, pocket_names[0] + '.pt'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be0bc5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# What's in the training dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m systems \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m pocket_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(systems\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# What surfaces exist\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# What's in the training dataset\n",
    "systems = pickle.load(open('/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p', 'rb'))\n",
    "pocket_names = list(systems.keys())\n",
    "\n",
    "# What surfaces exist\n",
    "surface_dir = '/root/atomsurf/data/masif_ligand/surf_1.0_False'\n",
    "surface_files = set([f.replace('.pt', '') for f in os.listdir(surface_dir)])\n",
    "\n",
    "# Find the mismatch\n",
    "missing = []\n",
    "for pocket in pocket_names:\n",
    "    if pocket not in surface_files:\n",
    "        missing.append(pocket)\n",
    "\n",
    "print(f\"Training pockets: {len(pocket_names)}\")\n",
    "print(f\"Surface files available: {len(surface_files)}\")\n",
    "print(f\"Missing surfaces: {len(missing)}\")\n",
    "print(f\"\\nMissing rate: {len(missing)/len(pocket_names)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e022e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training pocket names:\n",
      "  3O7W_A_patch_0_SAM\n",
      "  4YTP_ACBD_patch_0_FAD\n",
      "  4YTP_ACBD_patch_1_HEM\n",
      "  4YMP_A_patch_0_HEM\n",
      "  4IVM_B_patch_0_FAD\n",
      "\n",
      "Sample surface file names:\n",
      "  3OZV_A_patch_0_HEM\n",
      "  6FQY_AB_patch_0_NAP\n",
      "  4XQ9_AB_patch_1_NAD\n",
      "  4DCA_A_patch_0_ADP\n",
      "  2C2C_A_patch_0_HEM\n",
      "\n",
      "Example missing pocket: 3O7W_A_patch_0_SAM\n",
      "Similar surface files found: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load training pockets\n",
    "systems = pickle.load(open('/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p', 'rb'))\n",
    "pocket_names = list(systems.keys())\n",
    "\n",
    "# Get surface files\n",
    "surface_dir = '/root/atomsurf/data/masif_ligand/surf_1.0_False'\n",
    "surface_files = [f.replace('.pt', '') for f in os.listdir(surface_dir)]\n",
    "\n",
    "# Sample comparison\n",
    "print(\"Sample training pocket names:\")\n",
    "for i in range(5):\n",
    "    print(f\"  {pocket_names[i]}\")\n",
    "\n",
    "print(\"\\nSample surface file names:\")\n",
    "for i in range(5):\n",
    "    print(f\"  {surface_files[i]}\")\n",
    "\n",
    "# Check one specific missing pocket\n",
    "missing_example = None\n",
    "for pocket in pocket_names:\n",
    "    if pocket not in surface_files:\n",
    "        missing_example = pocket\n",
    "        break\n",
    "\n",
    "if missing_example:\n",
    "    print(f\"\\nExample missing pocket: {missing_example}\")\n",
    "    \n",
    "    # Check for similar names\n",
    "    similar = [s for s in surface_files if missing_example.split('_')[0] in s]\n",
    "    print(f\"Similar surface files found: {len(similar)}\")\n",
    "    if similar:\n",
    "        print(f\"Examples:\")\n",
    "        for s in similar[:3]:\n",
    "            print(f\"  {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131756fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All patches (from dataset_MasifLigand): 2254\n",
      "Training pockets (from train.p): 1972\n",
      "\n",
      "Overlap: 1634\n",
      "In preprocessing but not in training: 620\n",
      "In training but not in preprocessing: 338\n",
      "\n",
      "First 5 missing from preprocessing:\n",
      "  1PFK_ACBD_patch_6_ADP\n",
      "  1S4E_A_patch_0_ADP\n",
      "  2OYY_ABIKJL_patch_2_HEM\n",
      "  2PO0_ACBEDF_patch_1_ADP\n",
      "  5KF9_AB_patch_1_COA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# What preprocessing processes (strip .npz)\n",
    "patch_dir = '/root/atomsurf/data/masif_ligand/dataset_MasifLigand'\n",
    "all_patches_raw = os.listdir(patch_dir)\n",
    "all_patches = set([p.replace('.npz', '') for p in all_patches_raw])\n",
    "\n",
    "# What training uses\n",
    "systems = pickle.load(open('/root/atomsurf/data/masif_ligand/raw_data_MasifLigand/splits/train.p', 'rb'))\n",
    "train_pockets = set(systems.keys())\n",
    "\n",
    "# Check overlap\n",
    "overlap = all_patches.intersection(train_pockets)\n",
    "in_preprocessing_not_training = all_patches - train_pockets\n",
    "in_training_not_preprocessing = train_pockets - all_patches\n",
    "\n",
    "print(f\"All patches (from dataset_MasifLigand): {len(all_patches)}\")\n",
    "print(f\"Training pockets (from train.p): {len(train_pockets)}\")\n",
    "print(f\"\\nOverlap: {len(overlap)}\")\n",
    "print(f\"In preprocessing but not in training: {len(in_preprocessing_not_training)}\")\n",
    "print(f\"In training but not in preprocessing: {len(in_training_not_preprocessing)}\")\n",
    "\n",
    "if in_training_not_preprocessing:\n",
    "    print(f\"\\nFirst 5 missing from preprocessing:\")\n",
    "    for p in list(in_training_not_preprocessing)[:5]:\n",
    "        print(f\"  {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d0e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsurf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
